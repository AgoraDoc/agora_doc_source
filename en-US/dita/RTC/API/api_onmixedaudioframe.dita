<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="api_onmixedaudioframe">
    <title><ph keyref="onMixedAudioFrame"/></title>
    <shortdesc id="short"><ph id="shortdesc">Retrieves the mixed captured and playback audio frame.</ph></shortdesc>
    <prolog>
        <metadata>
   <keywords>
       <indexterm keyref="onMixedAudioFrame" />
   </keywords>
        </metadata>
    </prolog>
    <refbody><section id="prototype">
        <p outputclass="codeblock">
                <codeblock props="android" outputclass="language-java">public abstract boolean onMixedAudioFrame(int type, int samplesPerChannel, int bytesPerSample, int channels, int samplesPerSec, ByteBuffer buffer, long renderTimeMs, int avsync_type);</codeblock>
                <codeblock props="ios mac" outputclass="language-objectivec">- (BOOL)onMixedAudioFrame:(AgoraAudioFrame* _Nonnull)frame;</codeblock>
                <codeblock props="windows" outputclass="language-cpp">virtual bool onMixedAudioFrame(AudioFrame&amp; audioFrame) = 0;</codeblock>
                <codeblock props="electron" outputclass="language-typescript"/>
                <codeblock props="unity" outputclass="language-csharp"/>
                <codeblock props="rn" outputclass="language-typescript"/>
                <codeblock props="flutter" outputclass="language-dart"/>
        </p>
        </section>
        <section id="detailed_desc">
   
   <p>
       <note type="attention">This callback only returns the single-channel data.</note>
   </p>
        </section>
        <section id="parameters"><title>Parameter</title>
   <parml  props="ios mac windows">
       <plentry>
  <pt props="windows">audioFrame</pt>
                    <pt props="ios mac">frame</pt>
  <pd>音频原始数据。 For details, see <xref keyref="AudioFrame"/>.</pd>
       </plentry>
   </parml>
            <parml props="android">
                <plentry id="type">
                    <pt>type</pt>
                    <pd>音频数据的类型。</pd>
                </plentry>
                <plentry id="samplesPerChannel">
                    <pt>samplesPerChannel</pt>
                    <pd>The number of samples per channel in the audio frame.</pd>
                </plentry>
                <plentry id="bytesPerSample">
                    <pt>bytesPerSample</pt>
                    <pd>每个采样点的字节数（byte）。 对于 PCM 音频数据，一般是两个字节。</pd>
                </plentry>
                <plentry id="channels">
                    <pt>channels</pt>
                    <pd><p>The number of channels.<ul>
                            <li>1: Mono.</li>
                            <li>2: Stereo. 双声道的音频数据是交叉存储的。</li>
                        </ul></p>
                    </pd>
                </plentry>
                <plentry id="samplesPerSec">
                    <pt>samplesPerSec</pt>
                    <pd>音频采样率（Hz）。</pd>
                </plentry>
                <plentry id="buffer">
                    <pt>buffer</pt>
                    <pd>The video buffer. buffer 大小为 samplesPerChannel x channels x bytesPerSample。</pd>
                </plentry>
                <plentry id="renderTimeMs">
                    <pt>renderTimeMs</pt>
                    <pd>The timestamp (ms) of the external audio frame. You can use this parameter for the following purposes: Restore the order of the captured audio frame. Synchronize audio and video frames in video-related scenarios, including where external video sources are used.</pd>
                </plentry>
                <plentry id="avsync">
                    <pt>avsync_type</pt>
                    <pd>Reserved for future use.</pd>
                </plentry>
            </parml>
        </section>
        <section id="return_values">
   <title>Returns</title>
   <ul>
       <li><codeph><ph keyref="true"/></codeph>: 音频帧数据有效，数据会被发送。</li>
       <li><codeph><ph keyref="false"/></codeph>: 音频帧数据无效，数据会被舍弃。</li>
   </ul>
        </section></refbody>
</reference>
